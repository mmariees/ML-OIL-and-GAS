{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p_gIGtkn6xc"
   },
   "source": [
    "# Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C73A5rjkn6xe"
   },
   "source": [
    "![](https://drive.google.com/uc?id=13kmqLXa-3FBUJq0Q3XVOkz8TENpVTkqk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex3JRig7n6xf"
   },
   "source": [
    "*Source: https://www.upnxtblog.com/index.php/2017/12/06/17-machine-learning-algorithms-that-you-should-know/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofgndOdAn6xg"
   },
   "source": [
    "Сами по себе решающие деревья используются в машинном обучении относительно редко, однако очень распространены методы, основанные на их композиции - ансамблях (Random Forest, XGBoost, LightGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm-fK1NNn6xh"
   },
   "source": [
    "## Линейные модели или решающие деревья?\n",
    "\n",
    "- когда данные хорошо линейно разделимы, линейная модель лучше\n",
    "\n",
    "- когда данные плохо линейно разделимы (много сложных нелинейных зависимостей в данных), модель, основанная на решающих деревьях, лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rL_WGjBln6xh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4m5UZ7Qn6xk"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (11, 6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD8HeNEgn6xn"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "n = 500\n",
    "X = np.zeros(shape=(n, 2))\n",
    "X[:, 0] = np.linspace(-5, 5, 500)\n",
    "X[:, 1] = X[:, 0] + 0.5 * np.random.normal(size=n)\n",
    "y = (X[:, 1] > X[:, 0]).astype(int)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap='winter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_tuMxIin6xp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6iZfU-vn6xs"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=13)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-cMtWocn6xv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqkBSH-mn6xy"
   },
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFadRElkn6x0"
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, lr)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQS5npyrn6x2"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27dpuKQ4n6x5"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_dt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9M5kTa4n6x7"
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vq4TenGn6x9"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X = np.random.randn(500, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0).astype(int)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap='winter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBWUfJ-mn6x_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1oI6rqjn6yB"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=13)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "accuracy_score(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cp5048Nnn6yE"
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test, y_test, lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__b6eYvWn6yG"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_score(y_pred_dt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gFwfqcyn6yI"
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test, y_test, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcCcyvQAn6yK"
   },
   "source": [
    "## Переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgIPmShSn6yL"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "n = 100\n",
    "X = np.random.normal(size=(n, 2))\n",
    "X[:50, :] += 0.25\n",
    "X[50:, :] -= 0.25\n",
    "y = np.array([1] * 50 + [0] * 50)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y, cmap='winter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKg_otSSn6yP"
   },
   "source": [
    "Как влияют разные значения гиперпараметров решающего дерева на его структуру?\n",
    "\n",
    "- `max_depth`: максимальная глубина дерева\n",
    "- `min_samples_leaf`: минимальное число объектов в вершине дерева, необходимое для того, чтобы она стала листовой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40dsDAa0n6yQ"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "\n",
    "for i, max_depth in enumerate([3, 5, None]):\n",
    "    for j, min_samples_leaf in enumerate([15, 5, 1]):\n",
    "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "        dt.fit(X, y)\n",
    "        ax[i][j].set_title('max_depth = {} | min_samples_leaf = {}'.format(max_depth, min_samples_leaf))\n",
    "        ax[i][j].axis('off')\n",
    "        plot_decision_regions(X, y, dt, ax=ax[i][j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCP6tmKhn6yS"
   },
   "source": [
    "На любой выборке (исключая те, где есть объекты с одинаковыми значениями признаков, но разными ответами) можно получить нулевую ошибку - с помощью максимально переобученного дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq6SsxV0n6yT"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, random_state=13)\n",
    "dt.fit(X, y)\n",
    "plot_decision_regions(X, y, dt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACNfP5w3n6yV"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y, dt.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwuCDfONn6yW"
   },
   "source": [
    "## Неустойчивость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UQNA6DAn6yX"
   },
   "source": [
    "Посмотрим, как будет меняться структура дерева, если брать для обучения разные 90%-ые подвыборки исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSifA8knn6yX"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        seed_idx = 3 * i + j\n",
    "        np.random.seed(seed_idx)\n",
    "        dt = DecisionTreeClassifier(random_state=13)\n",
    "        idx_part = np.random.choice(len(X), replace=False, size=int(0.9 * len(X)))\n",
    "        X_part, y_part = X[idx_part, :], y[idx_part]\n",
    "        dt.fit(X_part, y_part)\n",
    "        ax[i][j].set_title('sample #{}'.format(seed_idx))\n",
    "        ax[i][j].axis('off')\n",
    "        plot_decision_regions(X_part, y_part, dt, ax=ax[i][j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cD44uRtkn6yZ"
   },
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvsjuHYdn6ya"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us7VTlRBn6yc"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAbQTj_jn6ye"
   },
   "outputs": [],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Y_juatLn6yg"
   },
   "outputs": [],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSRFKN2Sn6yj"
   },
   "outputs": [],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArgWIAxln6yl"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=boston['data'], columns=boston['feature_names'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLcLIi_2n6yn"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VO4cOR6n6yp"
   },
   "outputs": [],
   "source": [
    "y = boston['target']\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WDoNxqtn6yr"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRWYJ-VJn6ys"
   },
   "outputs": [],
   "source": [
    "plt.title('House price distribution')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('# samples')\n",
    "plt.hist(y, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFuaXFM9n6yv"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K28xrtidn6yx"
   },
   "source": [
    "## Решающее дерево своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIq2KBvDn6yx"
   },
   "source": [
    "$R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Критерий ошибки:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) + \\frac{|R_r|}{|R_m|}H(R_r) \\to \\min_{j, t}\n",
    "$$\n",
    "\n",
    "$R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "$H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6WRCskbn6yy"
   },
   "source": [
    "_Реализуйте подсчет критерия ошибки. Для этого реализуйте функции для подсчета значения критерия информативности, а также для разбиения вершины._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFM6Oh1en6yz"
   },
   "outputs": [],
   "source": [
    "def H(R):\n",
    "    pass\n",
    "\n",
    "\n",
    "def split_node(R_m, feature, t):\n",
    "    pass\n",
    "\n",
    "\n",
    "def q_error(R_m, feature, t):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5l7PUaBn6y1"
   },
   "source": [
    "_Переберите все возможные разбиения выборки по одному из признаков и постройте график критерия ошибки в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xISFgq5Zn6y1"
   },
   "outputs": [],
   "source": [
    "feature = '<choose feature>'\n",
    "Q_array = []\n",
    "feature_values = np.unique(X_train[feature])\n",
    "for t in feature_values:\n",
    "    Q_array.append(q_error(X_train, feature, t))\n",
    "plt.plot(feature_values, Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('Q error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs5nOxCjn6y3"
   },
   "source": [
    "_Напишите функцию, находящую оптимальное разбиение данной вершины по данному признаку._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRC9WVden6y3"
   },
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m, feature):\n",
    "    Q_array = []\n",
    "    feature_values = np.unique(R_m[feature])\n",
    "    for t in feature_values:\n",
    "        Q_array.append(q_error(R_m, feature, t))\n",
    "    opt_threshold = # your code here\n",
    "    return opt_threshold, Q_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQt6Jgk6n6y6"
   },
   "outputs": [],
   "source": [
    "t, Q_array = get_optimal_split(X_train, feature)\n",
    "plt.plot(np.unique(X_train[feature]), Q_array)\n",
    "plt.title(feature)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('Q error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaTsJUugn6y9"
   },
   "source": [
    "_Постройте графики критерия ошибки (в зависимости от количества объектов в левом поддереве) для каждого из признаков. Найдите признак, показывающий наилучшее качество. Какой это признак? Каков порог разбиения и значение качества? Постройте график критерия ошибки для данного признака в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE8u4LMLn6y-"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for f in X_train.columns:\n",
    "    t, Q_array = get_optimal_split(X_train, f)\n",
    "    min_error = min(Q_array)\n",
    "    results.append((f, t, min_error))\n",
    "    plt.figure()\n",
    "    plt.title('Feature: {} | optimal t: {} | min Q error: {:.2f}'.format(f, t, min_error))\n",
    "    plt.plot(np.unique(X_train[f]), Q_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU9oU49Gn6zA"
   },
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x[2])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycuRmXCVn6zC"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=['feature', 'optimal t', 'min Q error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbqqSjahn6zF"
   },
   "outputs": [],
   "source": [
    "optimal_feature, optimal_t, optimal_error = results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDsWgJ5On6zH"
   },
   "source": [
    "_Изобразите разбиение визуально. Для этого постройте диаграмму рассеяния целевой переменной в зависимости от значения найденного признака. Далее изобразите вертикальную линию, соответствующую порогу разбиения. Почему это разбиение может быть лучшим? Как вы можете интерпретировать результат?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5pI9gkmn6zH"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[optimal_feature], y)\n",
    "plt.axvline(x=optimal_t, color=\"red\")\n",
    "plt.xlabel(optimal_feature)\n",
    "plt.ylabel('target')\n",
    "plt.title('Feature: {} | optimal t: {} | Q error: {:.2f}'.format(optimal_feature, optimal_t, optimal_error))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEIR-n4hn6zK"
   },
   "source": [
    "## Решающее дерево: sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_qIyBZKn6zK"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(max_depth=3, random_state=13)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yRAAyF2n6zM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(dt, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K462JzXpn6zO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mc8NIWC2oPm_"
   },
   "outputs": [],
   "source": [
    "max_depth_array = range(2, 20)\n",
    "mse_array = []\n",
    "for max_depth in max_depth_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "plt.plot(max_depth_array, mse_array)\n",
    "plt.title('Dependence of MSE on max depth')\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImsdNpnhoQ1N"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'max_depth': max_depth_array,\n",
    "    'MSE': mse_array\n",
    "}).sort_values(by='MSE').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC0PHh9toSQN"
   },
   "outputs": [],
   "source": [
    "min_samples_leaf_array = range(1, 20)\n",
    "mse_array = []\n",
    "for min_samples_leaf in min_samples_leaf_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=6, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "plt.plot(min_samples_leaf_array, mse_array)\n",
    "plt.title('Dependence of MSE on min samples leaf')\n",
    "plt.xlabel('min samples leaf')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEBe9NbXoTpm"
   },
   "outputs": [],
   "source": [
    "min_samples_split_array = range(2, 20)\n",
    "mse_array = []\n",
    "for min_samples_split in min_samples_split_array:\n",
    "    dt = DecisionTreeRegressor(max_depth=6, min_samples_split=min_samples_split, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
    "plt.plot(min_samples_split_array, mse_array)\n",
    "plt.title('Dependence of MSE on min samples split')\n",
    "plt.xlabel('min samples split')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puW22Xc6n6zP"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=6, random_state=13)\n",
    "dt.fit(X_train, y_train)\n",
    "plot_tree(dt, feature_names=X.columns, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jP3kRvTen6zS"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQCRYsyXn6zU"
   },
   "outputs": [],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kW_i-L4Zn6zV"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': dt.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULLCGu7Kn6zW"
   },
   "source": [
    "Влияет ли стандартизация (масштабирование) признаков на результат работы решающего дерева?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnPQyzedn6zX"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV-b5l_nn6zY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(sc.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DuGDDgYn6zZ"
   },
   "outputs": [],
   "source": [
    "# without scaling\n",
    "for max_depth in [3, 6]:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train, y_train)\n",
    "    print(mean_squared_error(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIf1L2urn6zc"
   },
   "outputs": [],
   "source": [
    "# with scaling\n",
    "for max_depth in [3, 6]:\n",
    "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
    "    dt.fit(X_train_scaled, y_train)\n",
    "    print(mean_squared_error(y_test, dt.predict(X_test_scaled)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sem_trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
